{
  "activeProvider": "openai",
  "ollama": {
    "serverUrl": "http://localhost:11434",
    "model": "llama3"
  },
  "openai": {
    "apiKey": "",
    "baseUrl": "https://api.openai.com/v1",
    "model": "gpt-4o"
  },
  "model": "gemma3n:e2b",
  "serverUrl": "http://localhost:11434"
}