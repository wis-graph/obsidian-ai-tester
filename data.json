{
  "activeProvider": "ollama",
  "ollama": {
    "serverUrl": "http://localhost:11434",
    "model": "gemma3n:e2b"
  },
  "openai": {
    "apiKey": "",
    "baseUrl": "https://api.openai.com/v1",
    "model": "gpt-4o"
  }
}